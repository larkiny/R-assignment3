"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"ABCD2345","webpage","","Center for History and New Media","Zotero Quick Start Guide","","","","","http://zotero.org/support/quick_start_guide","","","2016-09-09 01:00:23","2016-09-09 01:00:23","","","","","","","","","","","","","","","","","","","","","","","<p><strong>Welcome to Zotero!</strong></p><p>View the Quick Start Guide to learn how to begin collecting, managing, citing, and sharing your research sources.</p><p>Thanks for installing Zotero.</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"66U4A25A","journalArticle","2010","Bowers, Alex J.","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students: Grades, Data Driven Decision Making, Dropping out and Hierarchical Cluster Analysis","Practical Assessment, Research & Evaluation","","1531-7714","","","School personnel currently lack an effective method to pattern and visually interpret disaggregated achievement data collected on students as a means to help inform decision making. This study, through the examination of longitudinal K-12 teacher assigned grading histories for entire cohorts of students from a school district (n=188), demonstrates a novel application of hierarchical cluster analysis and pattern visualization in which all data points collected on every student in a cohort can be patterned, visualized and interpreted to aid in data driven decision making by teachers and administrators. Additionally, as a proof-of-concept study, overall schooling outcomes, such as student dropout or taking a college entrance exam, are identified from the data patterns and compared to past methods of dropout identification as one example of the usefulness of the method. Hierarchical cluster analysis correctly identified over 80% of the students who dropped out using the entire student grade history patterns from either K-12 or K-8. (Contains 5 figures.)","2010-05","2016-09-13 16:05:30","2016-09-13 16:05:30","2014-09-24 19:31:29","","","7","15","","","Analyzing the Longitudinal K-12 Grading Histories of Entire Cohorts of Students","","","","","","","en","","","","","ERIC","","","<p>- One way to help visualize the organization of the data by hierarchical clustering is to draw a cluster tree, sometimes referred to as a dendrogram</p> <p>- A cluster tree is generated from the similarity matrix outlined above. For each iteration of the clustering algorithm, a line is drawn in the dendrogram as a graphical representation for each case. For each iteration of the algorithm, the cluster tree “grows” as the first level of clusters is connected to other clusters hierarchically, until the entire dataset is represented as a single cluster.</p> <p>- In the clustergram, the overall z-scored data for each case is unchanged, but is merely reordered for categorization and pattern interpretation based on how similar each case’s data vector is to each other case’s data vector.</p> <p>-&nbsp; x - students</p> <p>&nbsp;&nbsp;&nbsp; Y- subjects</p> <p>&nbsp;&nbsp;&nbsp; z-score</p> <p>&nbsp;&nbsp;&nbsp; results: identification of dropouts</p> <p>&nbsp;</p>","","http://eric.ed.gov/?id=EJ933686","","data; data analysis; Decision Making; Dropouts; Elementary School Students; Grades (Scholastic); Identification; MULTIVARIATE analysis; School Districts; Secondary School Students","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QB24Z62X","journalArticle","2014","Grunspan, Daniel Z.; Wiggins, Benjamin L.; Goodreau, Steven M.","Understanding Classrooms through Social Network Analysis: A Primer for Social Network Analysis in Education Research","CBE-Life Sciences Education","",", 1931-7913","10.1187/cbe.13-08-0162","http://www.lifescied.org/content/13/2/167","Social interactions between students are a major and underexplored part of undergraduate education. Understanding how learning relationships form in undergraduate classrooms, as well as the impacts these relationships have on learning outcomes, can inform educators in unique ways and improve educational reform. Social network analysis (SNA) provides the necessary tool kit for investigating questions involving relational data. We introduce basic concepts in SNA, along with methods for data collection, data processing, and data analysis, using a previously collected example study on an undergraduate biology classroom as a tutorial. We conduct descriptive analyses of the structure of the network of costudying relationships. We explore generative processes that create observed study networks between students and also test for an association between network position and success on exams. We also cover practical issues, such as the unique aspects of human subjects review for network studies. Our aims are to convince readers that using SNA in classroom environments allows rich and informative analyses to take place and to provide some initial tools for doing so, in the process inspiring future educational studies incorporating relational data.","2014-06-20","2016-09-13 16:05:31","2016-09-13 16:05:31","2014-08-20 20:21:46","167-178","","2","13","","CBE Life Sci Educ","Understanding Classrooms through Social Network Analysis","","","","","","","en","","","","","www.lifescied.org","","","<p>1. Social Network Basics. SNA aims to understand the determinants, structure, and consequences of relationships between actors. In other words, SNA helps us to understand how relationships form, what kinds of relational structures emerge from the building blocks of individual relationships between pairs of actors, and what, if any, the impacts are of these relationships on actors. Actors, also called nodes, can be individuals, organizations, websites, or any entity that can be connected to other entities. A group of actors and the connections between them make up a network.</p> <ul> <li>Node vertex</li> <li>Link edge&nbsp;(undirected directed reciprocal)</li> </ul> <p>2.Network Types.</p> <ul> <li>unipartite monopartite</li> <li>undirected directed (Indegree/ Outdegree)</li> <li>Ties: binary / valued</li> </ul> <p>3. Network Level :&nbsp; -&gt; social selection/ social influence</p> <ul> <li>Density</li> <li>Homophily</li> </ul> <p>4. Triads (3 nodes)</p> <ul> <li>triad census (2 actural3 possible density =0.67)</li> <li>transitivity</li> </ul> <p>5. Betweenness Centrality</p> <p>&nbsp; the # of the shortest paths from all nodes to all others that pass through that node.</p> <p>6. Force directed graphing</p> <ul> <li>Attractive forces</li> </ul> <p>&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; Springs</p> <p>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; Hooke's Law : F= kX</p> <ul> <li>Repulsive forces</li> </ul> <p>&nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp; Electrons</p> <p>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; <a href=""http://www.dephi.org"">www.dephi.org</a></p> <p>&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp; <a href=""http://www.lingaro.com"">www.lingaro.com</a></p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;&nbsp;&nbsp;</p> <p>&nbsp;</p>","","http://www.lifescied.org/content/13/2/167","Week 2","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BMD29UTE","blogPost","2014","Young, Jeffrey R.","Why Students Should Own Their Educational Data","The Chronicle of Higher Education Blogs: Wired Campus","","","","http://chronicle.com/blogs/wiredcampus/why-students-should-own-their-educational-data/54329","","2014-08-21","2016-09-13 16:05:31","2016-09-13 16:05:31","2014-08-23 21:32:22","","","","","","","","","","","","","","","","","","","","","","<p><span style=""color: #333333; font-family: Heuristica, 'Times New Roman', Times, serif; font-size: 18px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; display: inline !important; float: none;"">1st Problem is <span style=""color: #333333; font-family: Heuristica, 'Times New Roman', Times, serif; font-size: 18px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; display: inline !important; float: none;""><span class=""Apple-converted-space"">the </span>shift to a different way where you start by analyzing individual patterns instead of aggregate data.</span></span></p> <p><span style=""color: #333333; font-family: Heuristica, 'Times New Roman', Times, serif; font-size: 18px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; display: inline !important; float: none;"">2nd: Everyone is trying to innovate in their platform and say, here’s the thing. And there aren’t even interoperability standards or format standards.</span></p> <p><span style=""color: #333333; font-family: Heuristica, 'Times New Roman', Times, serif; font-size: 18px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; display: inline !important; float: none;"">3rd: <span style=""color: #333333; font-family: Heuristica, 'Times New Roman', Times, serif; font-size: 18px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; display: inline !important; float: none;"">the real value of the MOOCs so far, is that it’s forced a conversation,<span style=""color: #333333; font-family: Heuristica, 'Times New Roman', Times, serif; font-size: 18px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; display: inline !important; float: none;"">to ask what’s the value proposition of a four-year education.</span></span> </span></p>","","http://chronicle.com/blogs/wiredcampus/why-students-should-own-their-educational-data/54329","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CHQJ4MU5","journalArticle","1994","Corbett, Albert T.; Anderson, John R.","Knowledge tracing: Modeling the acquisition of procedural knowledge","User Modeling and User-Adapted Interaction","","0924-1868, 1573-1391","10.1007/BF01099821","http://link.springer.com.ezp-prod1.hul.harvard.edu/article/10.1007/BF01099821","This paper describes an effort to model students' changing knowledge state during skill acquisition. Students in this research are learning to write short programs with the ACT Programming Tutor (APT). APT is constructed around a production rule cognitive model of programming knowledge, called theideal student model. This model allows the tutor to solve exercises along with the student and provide assistance as necessary. As the student works, the tutor also maintains an estimate of the probability that the student has learned each of the rules in the ideal model, in a process calledknowledge tracing. The tutor presents an individualized sequence of exercises to the student based on these probability estimates until the student has ‘mastered’ each rule. The programming tutor, cognitive model and learning and performance assumptions are described. A series of studies is reviewed that examine the empirical validity of knowledge tracing and has led to modifications in the process. Currently the model is quite successful in predicting test performance. Further modifications in the modeling process are discussed that may improve performance levels.","1994-12-01","2016-09-13 16:05:31","2016-09-13 16:05:31","2013-04-21 21:21:19","253-278","","4","4","","User Model User-Adap Inter","Knowledge tracing","","","","","","","en","","","","","link.springer.com.ezp-prod1.hul.harvard.edu","","","<p>Can't open while requiring Harvard Key ID</p>","","","","Education (general); empirical validity; individual differences; intelligent tutoring systems; Learning; Management of Computing and Information Systems; mastery learning; Multimedia Information Systems; procedural knowledge; Psychology, general; student modeling; User Interfaces and Human Computer Interaction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N3KXD7PQ","conferencePaper","2012","Siemens, George; Baker, Ryan S. J. d.","Learning Analytics and Educational Data Mining: Towards Communication and Collaboration","Proceedings of the 2Nd International Conference on Learning Analytics and Knowledge","978-1-4503-1111-3","","10.1145/2330601.2330661","http://doi.acm.org/10.1145/2330601.2330661","Growing interest in data and analytics in education, teaching, and learning raises the priority for increased, high-quality research into the models, methods, technologies, and impact of analytics. Two research communities -- Educational Data Mining (EDM) and Learning Analytics and Knowledge (LAK) have developed separately to address this need. This paper argues for increased and formal communication and collaboration between these communities in order to share research, methods, and tools for data mining and analysis in the service of developing both LAK and EDM fields.","2012","2016-09-13 16:05:31","2016-09-13 16:05:31","2015-01-16 03:15:55","252–254","","","","","","Learning Analytics and Educational Data Mining","","","","","ACM","New York, NY, USA","","","","","","ACM Digital Library","","","<p>1. Differences b/w EDM &amp; LAK:</p> <ul> <li>EDM = Tech Field, LAK= ED Field</li> <li>EDM=automation, LAK= using tech as a tool to enhance human judgment</li> <li>Methodological differences: EDM=machine learning, LAK= text &amp; SNA</li> <li>EDM = individual, LAK = holistic</li> <li>Challenge of integrating the tech and ed.</li> <li>Techniques &amp; M ethods: <br />LAK: Social network analysis, sentiment analysis, influence analytics, discourse analysis, learner success prediction, concept analysis, sensemaking models; <br />EDM: Classification, clustering, Bayesian modeling, relationship mining, discovery with models, visualization;</li> </ul> <p>&nbsp;</p> <p>2. First workshop holding in 2005, @Pittsburgh</p> <p>&nbsp;&nbsp;&nbsp; First Conference @ Montreal, in 2008</p> <p>3.</p> <ul> <li style=""text-align: left;"">“Educational Data Mining is an emerging discipline, concerned with developing methods for exploring the unique types of data that come from educational settings, and using those methods to better understand students, and the settings which they learn in.""</li> <li style=""text-align: left;"">The Society for Learning Analytics Research defines Learning Analytics as: “… the measurement, collection, analysis and reporting of data about learners and their contexts, for purposes of understanding and optimizing learning and the environments in which it occurs.”</li> </ul> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p>","","","","Collaboration; educational data mining; learning analytics and knowledge","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XXNT9VPT","book","2015","Zheng, Alice","Evaluating Machine Learning Models","","","","","http://www.oreilly.com/data/free/evaluating-machine-learning-models.csp?intcmp=il-data-free-lp-lgen_free_reports_page","Data science today is a lot like the Wild West: there’s endless opportunity and excitement, but also a lot of chaos and confusion. If you’re new to data science and applied machine learning, evaluating a machine-learning model can seem pretty overwhelming...","2015-09","2016-09-13 16:05:31","2016-09-13 16:05:31","2015-12-15 18:26:39","","","","","","","","","","","","O'Reily Media","Sebastopol, CA","","","","","","","","","<p>1. Binary Classification</p> <ul> <li>generic names for the two classes: “positive” and “negative,” or “class 1” and “class 0.”</li> </ul> <ul> <li>measures: Accuracy, confusion matrix, log-loss, and AUC</li> <li>accuracy = # correct predictions/ # total data points</li> <li>confusion matrix: how many examples failed for class 0 versus class 1;<br />&nbsp;examples on pg 9 :<br />positive class has lower accuracy (80/(20 + 80) = 80%) than the negative class (195/ (5 + 195) = 97.5%).</li> <li>Per-Class Accuracy : as above (80% + 97.5%)/2 = 88.75%</li> <li>log-loss is the cross entropy between the dis‐ tribution of the true labels and the prediction; By minimizing the cross entropy, we maximize the accuracy of the classifier.</li> <li>AUC stands for area under the curve (ROC): The ROC curve shows the sensi‐ tivity of the classifier by plotting the rate of true positives to the rate of false positives (hard to compare/ details in classifiers)</li> <li>A bad ROC curve covers very little area. So high AUC is good, and low AUC is not so good.</li> </ul> <p>2.Ranking Metrics</p> <ul> <li>Precision-Recall:</li> </ul> <p>precision = # happy correct answers/ # total items returned by ranker</p> <p>recall = # happy correct answers /# total relevant items</p> <ul> <li>Precision-Recall Curve and the F1 Score: F1 score will be small if either precision or recall is small (p14)</li> <li>NDCG :normalized discounted cumulative gain. -Cumulative gain sums up the relevance of the top k items. Discounted cumulative gain discounts items that are further down the list. Normalized discounted cumulative gain, true to its name, is a nor‐ malized version of discounted cumulative gain. It divides the DCG by the perfect DCG score, so that the normalized score always lies between 0.0 and 1.0.</li> </ul> <p>3. Regression Metrics</p> <ul> <li>RMSE (root-mean-square error)</li> <li>Quantiles of Errors :mean is not robust (to large outliers) if produce large average error</li> </ul> <p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; median absolute percentage&nbsp; to look at robust estimators of performance , with “Almost Correct” Predictions (p16)</p>","/Users/jiaxil/Desktop/CU/CU_HWS/Autumn 2016/EDM/evaluating-machine-learning-models.pdf; ","http://www.oreilly.com/data/free/evaluating-machine-learning-models.csp?intcmp=il-data-free-lp-lgen_free_reports_page","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BKH3EJ6N","blogPost","2015","Leong, B; Polonetsky, J","Why Opting Out of Student Data Collection Isn’t the Solution","EdSurge","","","","https://www.edsurge.com/news/2015-03-16-why-opting-out-of-student-data-collection-isn-t-the-solution","In every privacy debate across every industry, the same questions arise about the rights of individuals to “opt-out” of their data being collected or used. So it should come as no surprise that the “when” and “how” of parent and student opt-outs of education data collection or use has become a robust","2015-03-16","2016-09-13 16:05:31","2016-09-13 16:05:31","2016-01-16 16:31:25","","","","","","","","","","","","","","","","","","","","","","<ul> <li>It is useful and needed to collect data under the base of administrative office</li> <li>should not be lack of knowledge and understandings on students with diverse backgrounds</li> <li>when it is not used for educational purpose, then parents should refuse</li> <li><span style=""color: #333333; font-family: Merriweather, Georgia, 'Times New Roman', serif; font-size: 18px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: -0.54px; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; display: inline !important; float: none;"">Opt-out rights should be an opportunity for parents to decline uses of data that truly are secondary to the functioning of our educational system – not an opportunity to avoid resolution of education policy issues that affect all students.</span></li> </ul>","","https://www.edsurge.com/news/2015-03-16-why-opting-out-of-student-data-collection-isn-t-the-solution","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VVRFMHFG","videoRecording","2015","Educause","Why Is Measuring Learning So Difficult?","","","","","https://www.youtube.com/watch?v=_iv8A1pHNYA","Several higher education learning and assessment professionals discuss the difficulties of measuring learning.","2015-08-17","2016-09-13 16:05:31","2016-09-13 16:05:31","2016-01-17 18:50:57","","","","","","","","","","","","","","","","","","","YouTube","","","<p>&nbsp;Why is it so difficult to measure learning?</p> <ul> <li>Don't know where a student is starting from</li> <li>Cant measure all the ways that people learn</li> <li>Based on proxies, but proxies change based on context not just individual</li> <li>We can simplify but may throw away the signal and keep the noise</li> </ul>","","","","Assessment; Education; educational assessment; EDUCAUSE; Higher Education; learners; Learning; Teaching and learning","","","","","","","","","","","","","","","","","","","","","470 seconds","","","","","","","","","","","","","","","","","","","","","","","","",""
"D5SXF6K4","webpage","2016","Weinersmith, Zach","Saturday Morning Breakfast Cereal","","","","","http://www.smbc-comics.com/index.php?id=3978","","2016-01-05","2016-09-13 16:05:31","2016-09-13 16:05:31","2016-01-18 18:17:09","","","","","","","","","","","","","","","","","","","","","","","","http://www.smbc-comics.com/index.php?id=3978","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DVWF6K2T","conferencePaper","2014","Clow, Doug","Data wranglers: human interpreters to help close the feedback loop","Proceedings of the Fourth International Conference on Learning Analytics And Knowledge","","","","","","2014","2016-09-13 16:05:31","2016-09-13 16:05:31","","49–53","","","","","","","","","","","ACM","","","","","","","","","","<p><a href=""http://garrettgman.github.io/tidying/"">http://garrettgman.github.io/tidying/</a></p> <p>&nbsp;<a href=""http://oro.open.ac.uk/40608/2/Clow-DataWranglers-final.pdf"">http://oro.open.ac.uk/40608/2/Clow-DataWranglers-final.pdf</a></p> <p>&nbsp;</p> <p>The aim of the Data Wranglers is to improve the learning experience</p> <p>The Data Wranglers are a group of academics who analyse data about student learning and prepare reports with actionable recommendations based on that data.</p> <p>There is a Data Wrangler for each of the OU’s seven academic Faculties, and so far as possible the Data Wranglers are selected to have an academic background close to the Faculty they are working with.</p> <p>Their role is to translate the theory described above in to practice: to act as human sense-makers, facilitating action on feedback from learners, making better sense of what that feedback means and how the data can be improved (double-loop learning), and helping to develop the Community of Practice around the use of learning analytic</p> <p>&nbsp;</p> <p>The Data Wranglers work with four main data sources:&nbsp; Survey feedback data from students, gathered at the end of their course; Activity data from the VLE/LMS (Moodle).; Delivery data about the mode of delivery and structure of courses (e.g. what use each course makes of online forums).; Aggregated completion, pass rate and demographic data.</p> <p>&nbsp;</p> <p>&nbsp;</p> <p>&nbsp;</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"54KWB96W","videoRecording","2015","Georgia Tech","Feature Selection","","","","","https://www.youtube.com/watch?v=8CpRLplmdqE","","2015-02-23","2016-09-13 16:05:31","2016-09-13 16:05:31","2016-01-18 19:18:06","","","","","","","","","","","","Youtube","","","","","","","","","","","","https://www.youtube.com/watch?v=8CpRLplmdqE","","","","","","","","","","","","","","","Udacity","","","","","","","","3:13","","","","","","","","","","","","","","","","","","","","","","","","",""
"TRDRSX28","bookSection","2016","Hanneman, R.A.; Riddle, M.","Chapter 1: Social Network Data","Introduction to Social Network Methods","","","","http://faculty.ucr.edu/~hanneman/nettext/C1_Social_Network_Data.html","","2016-01-18","2016-09-13 16:05:31","2016-09-13 16:05:31","2016-01-18 20:17:24","","","","","","","","","","","","","","","","","","","","","","","","http://faculty.ucr.edu/~hanneman/nettext/C1_Social_Network_Data.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FMJNXWKV","webpage","2014","Groelmund, Garrett","RStudio Cheat Sheets","RStudio","","","","https://www.rstudio.com/resources/cheatsheets/","","2014-08-01","2016-09-13 16:05:31","2016-09-13 16:05:31","2016-01-19 21:17:28","","","","","","","","","","","","","","","","","","","","","","","","http://shiny.rstudio.com/articles/rm-cheatsheet.html","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3TM7VGCW","journalArticle","2012","Greller, Wolfgang; Drachsler, Hendrik","Translating Learning into Numbers: A Generic Framework for Learning Analytics","Journal of Educational Technology & Society","","1176-3647","","http://www.jstor.org/stable/jeductechsoci.15.3.42","ABSTRACT With the increase in available educational data, it is expected that Learning Analytics will become a powerful means to inform and support learners, teachers and their institutions in better understanding and predicting personal learning needs and performance. However, the processes and requirements behind the beneficial application of Learning and Knowledge Analytics as well as the consequences for learning and teaching are still far from being understood. In this paper, we explore the key dimensions of Learning Analytics (LA), the critical problem zones, and some potential dangers to the beneficial exploitation of educational data. We propose and discuss a generic design framework that can act as a useful guide for setting up Learning Analytics services in support of educational practice and learner guidance, in quality assurance, curriculum development, and in improving teacher effectiveness and efficiency. Furthermore, the presented article intends to inform about soft barriers and limitations of Learning Analytics. We identify the required skills and competences that make meaningful use of Learning Analytics data possible to overcome gaps in interpretation literacy among educational stakeholders. We also discuss privacy and ethical issues and suggest ways in which these issues can be addressed through policy guidelines and best practice examples.","2012","2016-09-13 16:05:31","2016-09-13 16:05:31","2016-09-03 18:55:41","42-57","","3","15","","Journal of Educational Technology & Society","Translating Learning into Numbers","","","","","","","","","","","","JSTOR","","","<p><a href=""https://www.jstor.org/stable/pdf/jeductechsoci.15.3.42.pdf"">https://www.jstor.org/stable/pdf/jeductechsoci.15.3.42.pdf</a></p> <p>&nbsp;</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AXBFN2QH","bookSection","2006","Kay, Judy; Maisonneuve, Nicolas; Yacef, Kalina; Reimann, Peter","The Big Five and Visualisations of Team Work Activity","Intelligent Tutoring Systems","978-3-540-35159-7 978-3-540-35160-3","","","http://link.springer.com/chapter/10.1007/11774303_20","We have created a set of novel visualisations of group activity: they mirror activity of individuals and their interactions, based upon readily available authentic data. We evaluated these visualisations in the context of a semester long software development project course. We give a theoretical analysis of the design of our visualizations using the framework from the “Big 5” theory of team work as well as a qualitative study of the visualisations and the students’ reflective reports. We conclude that these visualisations provide a powerful and valuable mirroring role with potential, when well used, to help groups learn to improve their effectiveness.","2006-06-26","2016-09-13 16:05:31","2016-09-13 16:05:31","2016-09-03 19:10:12","197-206","","","","","","","","","","","Springer Berlin Heidelberg","","en","©2006 Springer-Verlag Berlin Heidelberg","","","","link.springer.com","","","<p><a href=""http://download.springer.com/static/pdf/954/chp%253A10.1007%252F11774303_20.pdf?originUrl=http%3A%2F%2Flink.springer.com%2Fchapter%2F10.1007%2F11774303_20&amp;token2=exp=1475595868~acl=%2Fstatic%2Fpdf%2F954%2Fchp%25253A10.1007%25252F11774303_20.pdf%3ForiginUrl%3Dhttp%253A%252F%252Flink.springer.com%252Fchapter%252F10.1007%252F11774303_20*~hmac=bc22a80e6caedf45cf6493a483b4747fd1f8943edd247c108afe832492c72267"">http://download.springer.com/static/pdf/954/chp%253A10.1007%252F11774303_20.pdf?originUrl=http%3A%2F%2Flink.springer.com%2Fchapter%2F10.1007%2F11774303_20&amp;token2=exp=1475595868~acl=%2Fstatic%2Fpdf%2F954%2Fchp%25253A10.1007%25252F11774303_20.pdf%3ForiginUrl%3Dhttp%253A%252F%252Flink.springer.com%252Fchapter%252F10.1007%252F11774303_20*~hmac=bc22a80e6caedf45cf6493a483b4747fd1f8943edd247c108afe832492c72267</a></p> <ul> <li>need to demonstrate date graphically</li> </ul> <ul> <li>need to demonstrate a point</li> </ul> <ul> <li>but not distort the data to make a point</li> </ul> <ul> <li>description, exploration, tabulation or decoration</li> </ul>","","https://link.springer.com/chapter/10.1007/11774303_20","","Artificial Intelligence (incl. Robotics); Computers and Education; Information Systems Applications (incl. Internet); Multimedia Information Systems; User Interfaces and Human Computer Interaction","Ikeda, Mitsuru; Ashley, Kevin D.; Chan, Tak-Wai","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M7A72KQ5","journalArticle","2015","Konstan, Joseph A.; Walker, J. D.; Brooks, D. Christopher; Brown, Keith; Ekstrand, Michael D.","Teaching Recommender Systems at Large Scale: Evaluation and Lessons Learned from a Hybrid MOOC","ACM Trans. Comput.-Hum. Interact.","","1073-0516","10.1145/2728171","http://doi.acm.org/10.1145/2728171","","2015-04","2016-09-13 16:05:31","2016-09-13 16:05:31","2016-09-03 20:38:02","10:1–10:23","","2","22","","","Teaching Recommender Systems at Large Scale","","","","","","","","","","","","ACM Digital Library","","","<p>1. RESEARCH GOALS</p> <ul> <li>Do students learn in this MOOC?&nbsp;</li> <li>a face-to-face recommender systems MOOC &gt; a comparable group of MOOC students</li> <li>What demographic, background, and behavioral factors predict course completion, normalized subject matter learning gains</li> <li>What is the interaction between learning (and practicing) concept subject matter on recommender systems and learning (and practicing) the programming of that subject matter in the context of a MOOC?</li> <li>What are different types of reasons for taking this MOOC?</li> <li>Do the MOOC students retain what they learned?</li> </ul> <p>2. RESEARCH METHODS</p> <ul> <li>&nbsp;pretest-posttest nonequivalent groups design</li> <li>39 students in the face-to-face section of CSci 5980: Recommender Systems as well as approximately 4,844 students who completed a precourse survey</li> </ul> <p>3.RESULTS</p> <ul> <li>vast majority of students (72.5%) who completed the precourse survey intended to complete the entire course, rather than only certain parts, or the course material but not the assignments.</li> <li>a large majority of students (72.4%) reported that they completed as much or more of the MOOC than they had intended to.</li> <li>nearly all of the students (95.75%) who said they completed lessof the MOOC than they intended also reported that they found the experience useful nonetheless.</li> <li>knowledge, experience, and strong intentions influenced both measures of completion.</li> <li>The higher a student’s score on the knowledge pretest, the greater the number of MOOCs she had taken in the past, and the stronger her intention to complete the course, the more likely was it that she would complete both the writing assignment and exam in question.</li> <li>Result: Intention predicts completion; little else does.</li> <li>Result: Student knowledge increased</li> <li>Result: Limited data suggests that face-to-face students learned at least as much as online-only students.</li> <li>Result: Students at all incoming knowledge levels benefited similarly from the course.</li> <li>Result: Students in the programming and concepts tracks had similar gains in concepts knowledge, but programming students gained further knowledge.</li> <li>Result: Normalized knowledge gains are very difficult to predict; measures of relevant effort were strongest.</li> <li>Result: Predicting student end-of-term performance is difficult; appropriate predictor variables may be lacking.</li> <li>Result: Among students who responded to a 5-month follow-up, most student learning gains were retained after 5 months. Programming students retained more than concepts students did; very limited data on face-to-face students suggests their retention is at least as high as that of online-only students.</li> </ul> <p>4.</p>","","","","learning assessment; Massively Online Open Course (MOOC)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4XWZ63U9","bookSection","2013","Desmarais, Michel C.; Naceur, Rhouma","A Matrix Factorization Method for Mapping Items to Skills and for Enhancing Expert-Based Q-Matrices","Artificial Intelligence in Education","978-3-642-39111-8 978-3-642-39112-5","","","http://link.springer.com/chapter/10.1007/978-3-642-39112-5_45","Uncovering the right skills behind question items is a difficult task. It requires a thorough understanding of the subject matter and of the cognitive factors that determine student performance. The skills definition, and the mapping of item to skills, require the involvement of experts. We investigate means to assist experts for this task by using a data driven, matrix factorization approach. The two mappings of items to skills, the expert on one side and the matrix factorization on the other, are compared in terms of discrepancies, and in terms of their performance when used in a linear model of skills assessment and item outcome prediction. Visual analysis shows a relatively similar pattern between the expert and the factorized mappings, although differences arise. The prediction comparison shows the factorization approach performs slightly better than the original expert Q-matrix, giving supporting evidence to the belief that the factorization mapping is valid. Implications for the use of the factorization to design better item to skills mapping are discussed.","2013-07-09","2016-09-13 16:05:31","2016-09-13 16:05:31","2016-09-03 20:44:11","441-450","","","","","","","","","","","Springer Berlin Heidelberg","","en","©2013 Springer-Verlag Berlin Heidelberg","","","","link.springer.com","","","<ul> <li> <h6><span style=""color: #222222; font-family: Roboto, arial, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; display: inline !important; float: none;"">Non-n</span><strong style=""color: #222222; font-family: Roboto, arial, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; letter-spacing: normal; orphans: 2; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff;"">atrix</strong><span style=""color: #222222; font-family: Roboto, arial, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; display: inline !important; float: none;"">approximation is a group of algorithms in multivariate analysis and linear algebra where a<span class=""Apple-converted-space"">&nbsp;</span></span><strong style=""color: #222222; font-family: Roboto, arial, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; letter-spacing: normal; orphans: 2; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff;"">matrix</strong><span style=""color: #222222; font-family: Roboto, arial, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; display: inline !important; float: none;""><span class=""Apple-converted-space"">&nbsp;</span>V is factorized into (usually) two<span class=""Apple-converted-space"">&nbsp;</span></span><strong style=""color: #222222; font-family: Roboto, arial, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; letter-spacing: normal; orphans: 2; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff;"">matrices</strong><span style=""color: #222222; font-family: Roboto, arial, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; display: inline !important; float: none;""><span class=""Apple-converted-space"">&nbsp;</span>W and H, with the property that all three<span class=""Apple-converted-space"">&nbsp;</span></span><strong style=""color: #222222; font-family: Roboto, arial, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; letter-spacing: normal; orphans: 2; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff;"">matrices</strong><span style=""color: #222222; font-family: Roboto, arial, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; display: inline !important; float: none;""><span class=""Apple-converted-space"">&nbsp;</span>have no negative elements.</span></h6> </li> <li><span style=""color: #222222; font-family: Roboto, arial, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; display: inline !important; float: none;""><span style=""color: #333333; font-family: Palatino, Georgia, 'Bitstream Charter', serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; display: inline !important; float: none;"">matrix factorization is to find out two (or more) matrices such that when you multiply them you will get back the original matrix</span></span></li> </ul> <p>&nbsp;</p>","; ","; https://link.springer.com/chapter/10.1007/978-3-642-39112-5_45","","alternating least squares matrix factorization; Artificial Intelligence (incl. Robotics); Cognitive modeling; Computers and Education; Educational Technology; Information Systems Applications (incl. Internet); latent skills; Pedagogic Psychology; skills assessment; Student models; User Interfaces and Human Computer Interaction","Lane, H. Chad; Yacef, Kalina; Mostow, Jack; Pavlik, Philip","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BZQE39MR","book","2015","Matsuda, Noboru; Furukawa, Tadanobu; Bier, Norman; Faloutsos, Christos","Machine Beats Experts: Automatic Discovery of Skill Models for Data-Driven Online Course Refinement","","","","","http://eric.ed.gov/?id=ED560513","How can we automatically determine which skills must be mastered for the successful completion of an online course? Large-scale online courses (e.g., MOOCs) often contain a broad range of contents frequently intended to be a semester's worth of materials; this breadth often makes it difficult to articulate an accurate set of skills and knowledge (i.e., a skill model, or the QMatrix). We have developed an innovative method to discover skill models from the data of online courses. Our method assumes that online courses have a pre-defined skill map for which skills are associated with formative assessment items embedded throughout the online course. Our method carefully exploits correlations between various parts of student performance, as well as in the text of assessment items, to build a superior statistical model that even outperforms human experts. To evaluate our method, we compare our method with existing methods (LFA) and human engineered skill models on three Open Learning Initiative (OLI) courses at Carnegie Mellon University. The results show that (1) our method outperforms human-engineered skill models, (2) skill models discovered by our method are interpretable, and (3) our method is remarkably faster than existing methods. These results suggest that our method provides a significant contribution to the evidence-based, iterative refinement of online courses with a promising scalability. [For complete proceedings, see ED560503.]","2015-06","2016-09-13 16:05:31","2016-09-13 16:05:31","2016-09-03 20:48:57","","","","","","","Machine Beats Experts","","","","","International Educational Data Mining Society","","en","","","","","ERIC","","","<p>1.</p> <ul> <li>eEPIPHANY : a matrix representing a chronological record of students’ responses to assessment items, called an A-matrix(3 dimensional)</li> </ul> <p>2.</p> <ul> <li>A - matrix: a history of attempts on individual assessment items made by individual students.</li> <li>Each attempt is a vector of binary values representing the correctness of a student’s response—0 indicates incorrect and 1 indicates correct.</li> <li>Q-matrix: goal of eEPIPHANY is to find a skill model (Q-matrix) that produces the best prediction of the A-matrix</li> </ul> <p>3.Methods:</p> <ul> <li>&nbsp;two latent-feature extraction strategies developed: (1) the Matrix Factorization (MF) strategy, and (2) the Bag-of-Words (BoW) strategy.</li> <li>MF: P-matrix: extraction strategies-&gt; a two-dimensional matrix, the P-Matrix, showing a mapping between assessment items and “skill candidates”</li> <li>&nbsp;BoW: creates the F-matrix directly from a collection of item stems (i.e., assessment item text data showing problem and feedback texts) for assessment items. That is, the assessment items are clustered by the bag-of-words method using item stems.</li> </ul> <p>4. Results</p> <ul> <li>with analyze the degree of enhancement (DoE), hypothesize that the DoE would be maximized among a skill(s) for which the accuracy of students’ performance prediction improved the most</li> <li>eEPIPHANY always yields a better skill model than the default skill model that is hand-crafted by human experts.</li> <li>As for the skill-model construction strategy, the replace strategy always discovers the best skill model</li> <li>(1) When the online course is initially implemented, we should apply eEPIPHANY with the bag-of-words strategy. (2) When the online course is actually used and student learning data are collected, then we should apply eEPIPHANY with the student data to further improve the course.</li> </ul>","","http://eric.ed.gov/?id=ED560513","","Automation; Comparative Analysis; Correlation; data; Formative Evaluation; models; Online Courses; Skills","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"98S4D6PB","conferencePaper","2008","Cortez, Paulo; Silva, Alice Maria Gonçalves","Using data mining to predict secondary school student performance","Proceedings of 5th Annual Future Business Technology Conference","978-90-77381-39-7","","","http://repositorium.sdum.uminho.pt/handle/1822/8024","Although the educational level of the Portuguese population has improved in the last decades, the statistics keep Portugal at Europe’s tail end due to its high student failure rates. In particular, lack of success in the core classes of Mathematics and the Portuguese language is extremely serious. On the other hand, the fields of Business Intelligence (BI)/Data Mining (DM), which aim at extracting high-level knowledge from raw data, offer interesting automated tools that can aid the education domain. The present work intends to approach student achievement in secondary education using BI/DM techniques. Recent real-world data (e.g. student grades, demographic, social and school related features) was collected by using school reports and questionnaires. The two core classes (i.e. Mathematics and Portuguese) were modeled under binary/five-level classification and regression tasks. Also, four DM models (i.e. Decision Trees, Random Forest, Neural Networks and Support Vector Machines) and three input selections (e.g. with and without previous grades) were tested. The results show that a good predictive accuracy can be achieved, provided that the first and/or second school period grades are available. Although student achievement is highly influenced by past evaluations, an explanatory analysis has shown that there are also other relevant features (e.g. number of absences, parent’s job and education, alcohol consumption). As a direct outcome of this research, more efficient student prediction tools can be be developed, improving the quality of education and enhancing school resource management.","2008-04","2016-09-13 16:05:31","2016-11-15 16:50:08","2016-09-04 01:23:19","","","","","","","","","","","","EUROSIS","Porto, Spain","eng","openAccess","","","","repositorium.sdum.uminho.pt","","http://repositorium.sdum.uminho.pt/bitstream/1822/8024/1/student.pdf","<p>1. Purpose:</p> <ul> <li>analyze recent real-world data from two Portuguese secondary schools. Two different sources were used: mark reports and questionnaires</li> </ul> <ul> <li>collection of several demographic, social and school related attributes (e.g. student’s age, alcohol consumption, mother’s education). The aim is to predict student achievement and if possible to identify the key variables that affect educational success/failure.</li> <li>The two core classes (i.e. Mathematics and Portuguese) will be modeled under DM</li> </ul> <p>2. Data collection:</p> <ul> <li>data collected during the 2005- 2006 school year from two public schools, from the Alentejo region of Portugal.</li> <li>from two sources: school reports,&nbsp; (i.e. the three period grades and number of school absences); and questionnaires,&nbsp; (i.e. with predefined options) related to several demographic (e.g. mother’s education, family income), social/emotional (e.g. alcohol consumption) (Pritchard and Wilson 2003) and school related (e.g. number of past class failures) variables</li> </ul> <p>3. Model:</p> <ul> <li>DT</li> <li>Cross-validation</li> </ul>","","http://repositorium.sdum.uminho.pt/handle/1822/8024","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","5th Annual Future Business Technology Conference","","","","","","","","","","","","","","",""
"G4ZU87VK","journalArticle","2008","Baker, Ryan S. J. d; Corbett, Albert T.; Roll, Ido; Koedinger, Kenneth R.","Developing a generalizable detector of when students game the system","User Modeling and User-Adapted Interaction","","0924-1868, 1573-1391","10.1007/s11257-007-9045-6","http://link.springer.com/article/10.1007/s11257-007-9045-6","Some students, when working in interactive learning environments, attempt to “game the system”, attempting to succeed in the environment by exploiting properties of the system rather than by learning the material and trying to use that knowledge to answer correctly. In this paper, we present a system that can accurately detect whether a student is gaming the system, within a Cognitive Tutor mathematics curricula. Our detector also distinguishes between two distinct types of gaming which are associated with different learning outcomes. We explore this detector’s generalizability, and find that it transfers successfully to both new students and new tutor lessons.","2008-01-23","2016-09-13 16:05:31","2016-09-13 16:05:31","2016-09-04 01:34:49","287-314","","3","18","","User Model User-Adap Inter","","","","","","","","en","","","","","link.springer.com","","","","","https://link.springer.com/article/10.1007/s11257-007-9045-6","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZR8MR5WF","book","2014","Baker, R","Big Data in Education","","","","","","","2014","2016-09-13 16:05:31","2016-09-13 16:05:31","","","","","","","","","","","","","","New York, NY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","1","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EQUCIS82","videoRecording","2016","Georgia Tech","Cross Validation","","","","","https://www.youtube.com/watch?v=sFO2ff-gTh0","","2016-09-09","2016-09-13 16:05:31","2016-09-13 16:05:31","2016-09-09 19:37:11","","","","","","","","","","","","Youtube","","","","","","","","","","","","https://www.youtube.com/watch?v=sFO2ff-gTh0","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PXR5GNW9","document","","","","","","","","","","","2016-09-13 16:35:42","2016-09-13 16:35:42","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B3X4AQWM","document","","","K means","","","","","https://www.cs.uic.edu/~wilkinson/Applets/cluster.html","","","2016-10-19 18:40:14","2016-10-19 18:42:12","","","","","","","","","","","","","","","","","","","","","","","<hr style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"" /> <h1 style=""color: #000000; font-family: Times; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">k-Means Clustering</h1> <p><span style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; display: inline !important; float: none;"">The k-means clustering algorithm classifies<span class=""Apple-converted-space"">&nbsp;</span></span><em style=""color: #000000; font-family: Times; font-size: medium; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">n</em><span style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; display: inline !important; float: none;""><span class=""Apple-converted-space"">&nbsp;</span>points into<span class=""Apple-converted-space"">&nbsp;</span></span><em style=""color: #000000; font-family: Times; font-size: medium; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">k</em><span style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; display: inline !important; float: none;""><span class=""Apple-converted-space"">&nbsp;</span>clusters by assigning each point to the cluster whose average value on a set of<span class=""Apple-converted-space"">&nbsp;</span></span><em style=""color: #000000; font-family: Times; font-size: medium; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">p</em><span style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; display: inline !important; float: none;"">variables is nearest to it by some distance measure (usually Euclidean) on that set. The algorithm computes these assignments iteratively, until reassigning points and recomputing averages (over all points in a cluster) produces no changes.</span></p> <p><br style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"" /><span style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; display: inline !important; float: none;"">Another way to describe the k-means algorithm is to define its goal geometrically. If<span class=""Apple-converted-space"">&nbsp;</span></span><em style=""color: #000000; font-family: Times; font-size: medium; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">n</em><span style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; display: inline !important; float: none;""><span class=""Apple-converted-space"">&nbsp;</span>points are embedded in a<span class=""Apple-converted-space"">&nbsp;</span></span><em style=""color: #000000; font-family: Times; font-size: medium; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">p</em><span style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; display: inline !important; float: none;"">-dimensional space, then<span class=""Apple-converted-space"">&nbsp;</span></span><em style=""color: #000000; font-family: Times; font-size: medium; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">k</em><span style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; display: inline !important; float: none;"">clusters are summarized by their respective centroids (average of the cluster members' coordinates) in that space. When k-means has finished iterating, the result partitions the set of points in this space using cutting planes (lines in 2D). Each cutting plane is positioned orthogonal to the line connecting a pair of cluster centroids so that it bisects that line. For<span class=""Apple-converted-space"">&nbsp;</span></span><em style=""color: #000000; font-family: Times; font-size: medium; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">k</em><span style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; display: inline !important; float: none;""><span class=""Apple-converted-space"">&nbsp;</span>clusters, there are<span class=""Apple-converted-space"">&nbsp;</span></span><em style=""color: #000000; font-family: Times; font-size: medium; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">k</em><span style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; display: inline !important; float: none;"">(</span><em style=""color: #000000; font-family: Times; font-size: medium; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">k</em><span style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; display: inline !important; float: none;"">-1)/2 cutting planes.<span class=""Apple-converted-space"">&nbsp;</span></span><br style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"" /><br style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"" /><span style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; display: inline !important; float: none;"">Computing a k-means clustering involves identifying a set of cluster centroids, which implicitly solves for these planes. There are many methods for finding a satisfactory set of centroids given a set of data. The simplest is to pick an initial set of centroid seeds randomly (assuming we know how many clusters we want) and to assign each point to its closest seed. After each assignment, we need to update the assigned centroid by adding in the coordinates of the new point (a simple calculation). Assigning all points to a set of successively updated centroids constitutes one iteration of the k-means algorithm.<span class=""Apple-converted-space"">&nbsp;</span></span><br style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"" /><br style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"" /><span style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; display: inline !important; float: none;"">Each new iteration consists of a re-assignment of all points, until no point can be moved to a centroid closer than the one for the cluster it is already a member of. Every time a point is re-assigned, its old centroid must be downdated and its new centroid must be updated.</span><br style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"" /><br style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"" /><span style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; display: inline !important; float: none;"">Starting with arbitrary random centroids is a relatively poor method, however. If there really are blobs of points, we do much better to begin with locations that are relatively close to the center of these blobs. John Hartigan (</span><em style=""color: #000000; font-family: Times; font-size: medium; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">Clustering Algorithms</em><span style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; display: inline !important; float: none;"">, Wiley, 1975) suggests a stagewise method to approach this goal. We begin with two centroids. These are computed by splitting all points on the variable (dimension) with greatest range (or some other measure of spread). The split separates points above the mean (or some other measure of location) on this variable from those below the mean. Centroids are then computed for each group by averaging coordinates of its members. Then we do an entire k-means cycle (assignments plus iterations). After convergence, we move to computing three centroids. Again, we split the cluster having the largest range on a variable into two clusters (one above and one below the mean on this variable). New centroids are computed and another k-means cycle is performed. We continue this process until we reach the desired number (</span><em style=""color: #000000; font-family: Times; font-size: medium; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">k</em><span style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; display: inline !important; float: none;"">)of centroids.</span><br style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"" /><br style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"" /><span style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; display: inline !important; float: none;"">If we do not know<span class=""Apple-converted-space"">&nbsp;</span></span><em style=""color: #000000; font-family: Times; font-size: medium; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">k</em><span style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; display: inline !important; float: none;""><span class=""Apple-converted-space"">&nbsp;</span>in advance, how can we choose a value based on our data? There is a circularity here: we need to know<span class=""Apple-converted-space"">&nbsp;</span></span><em style=""color: #000000; font-family: Times; font-size: medium; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">k</em><span style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; display: inline !important; float: none;""><span class=""Apple-converted-space"">&nbsp;</span>to find clusters and we need to identify clusters to determine<span class=""Apple-converted-space"">&nbsp;</span></span><em style=""color: #000000; font-family: Times; font-size: medium; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">k</em><span style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; display: inline !important; float: none;"">. Hartigan's procedure gives us a lever. At each stage of Hartigan's method, we compute the sum-of-squares within groups over all variables (sum of squared deviations of each point from its centroid on every dimension). This sum of squares should decline as we add new clusters; indeed, it would be zero if we made every point a cluster. So we look for the reduction in sum of squares at each step and stop adding clusters when this reduction is negligible. Hartigan gives an approximate<span class=""Apple-converted-space"">&nbsp;</span></span><em style=""color: #000000; font-family: Times; font-size: medium; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">F</em><span style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; display: inline !important; float: none;""><span class=""Apple-converted-space"">&nbsp;</span>statistic that can be used to test the ""significance"" of this reduction, but a simple method that works well for most datasets is to look for a proportional reduction in error (PRE) of about .4 or better to justify a split. PRE is the ratio of reduction in sum of squares to the previous sum of squares.</span><br style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"" /><br style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"" /><span style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; display: inline !important; float: none;"">The applet above computes a k-means clustering on two variables, using the PRE method to determine the number of clusters present. Each cluster is colored differently in the display. There are three random data distributions controlled by the buttons at the top. The first is Uniform random, the second is bivariate Normal, and the third is a mixture of bivariate normals (Lumpy). Every time you press the Sample button, you get a new random sample from these distributions. The size of these samples is controlled by the buttons at the bottom. The GIGO button at the bottom right stands for ""Garbage In, Garbage Out."" More about the GIGO button later.</span><br style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"" /><br style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"" /><span style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; display: inline !important; float: none;"">You should expect to see only one color for Uniform or Normal data (except occasionally for the smaller samples, where it is possible to get a blobby pattern by chance). And you should expect to see different colored clusters wherever they appear separated in the Lumpy display. In some cases you will see the straight cutting planes (lines) between clusters when overlapping blobs of points are cut apart. There will also be rare instances when clearly separated blobs are not identified. These are cases where the PRE statistic misses the cutoff (.4) by a small amount. There is always a tradeoff between false positives and false negatives, but we could improve this situation a bit by using more information than simple sums of squares.</span><br style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"" /><br style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"" /><span style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; display: inline !important; float: none;"">The applet also illustrates that k-means is most suited for separating convex clusters (clusters in which any line passing through a cluster intersects its boundary only twice). If your data contain doughnut-shaped or wormy-shaped clusters, don't expect k-means to find them.</span><br style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"" /><br style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"" /><span style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; display: inline !important; float: none;"">In general, k-means is a popular clustering method because it is simple to program and is easy to compute on large samples. Data mining programs incorporating k-means sometimes ignore the subtleties of the algorithm (updating, downdating, identifying an appropriate number of clusters, choosing suitable seeds, iterating enough times to converge). Ignoring these subtleties has its benefits, though: you will find nice clusters even when they don't exist in the data! To this end, I have given you a GIGO button to try. This button finds four clusters in anything. It uses random seeds, no updating/downdating, and iterates only once. For uniform random data, it produces a random Voronoi tessellation of the plane. For the lumpy data, it slices clusters as if a monkey were chopping beans.</span><br style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"" /><br style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"" /><span style=""color: #000000; font-family: Times; font-size: medium; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; display: inline !important; float: none;"">The GIGO button in a 2D applet lets you see the consequences of a badly designed k-means algorithm, but you would not perceive this as easily in higher dimensions. We humans are disposed to see patterns everywhere, even in random data. Thus, the insidious aspect of a badly designed cluster program is that it unfailingly gives us what we want.</span></p>; <p>1) The algorithm starts by randomly choosing some starting values <br />2) Associates all observations near to those values with them<br />3) Calculates the mean of those clusters of values<br />4) Selects the observation closest to the mean of the cluster<br />5) Re-associates all observations closest to this observation<br />6) Continues this process until the clusters are no longer changing</p>; <ul> <li>assumes there are clusters to find - it will find clusters regardless of whether there are any or not</li> <li>does not work on some shapes like PB&amp;J need an even spread</li> <li>need uniform scale uniform variance - larger scale will swamp smaller scale</li> <li>doesn't work on categorical data or more than two categories (and the scale may be difficult to interpret )</li> <li>can get stuck on local minima&nbsp; ( need to run iterations)</li> </ul>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CKXXZ5XP","document","","","assignment2","","","","","","","","2016-10-19 20:34:30","2016-10-19 20:34:41","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NZZPZSFZ","document","","","Data Tidying","","","","","http://garrettgman.github.io/tidying/","","","2016-10-19 20:53:36","2016-10-19 20:53:54","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VWUZAWCI","document","","","""Grammar of Graphics""","","","","","https://www.cs.uic.edu/~wilkinson/TheGrammarOfGraphics/GOG.html","a theory of how visualizations work best","","2016-10-19 21:06:05","2016-10-19 21:07:36","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KP92XTZD","document","","","Codes for Cluster Visualization","","","","","http://docs.ggplot2.org/current/","","","2016-10-19 21:08:06","2016-10-19 21:08:27","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V7J38WXC","document","","","kjhealy/revere","","","","","https://github.com/kjhealy/revere","","","2016-10-19 21:46:08","2016-10-19 21:46:20","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BGMPZJM2","document","","","two way tables","","","","","http://www.cyclismo.org/tutorial/R/tables.html","","","2016-10-19 21:51:14","2016-10-19 21:51:25","","","","","","","","","","","","","","","","","","","","","","","<div id=""contents"" class=""contents local topic"" style=""box-sizing: border-box; color: #404040; font-family: Lato, proxima-nova, 'Helvetica Neue', Arial, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #fcfcfc;""> <p class=""topic-title first"" style=""box-sizing: border-box; line-height: 24px; margin: 0px 0px 12px; font-size: 16px; font-weight: bold;"">Contents</p> <ul class=""simple"" style=""box-sizing: border-box; margin: 0px 0px 24px; padding: 0px; list-style: disc; line-height: 24px;""> <li style=""box-sizing: border-box; list-style: disc; margin-left: 24px;""><a id=""id1"" class=""reference internal"" style=""box-sizing: border-box; color: #4a9470; text-decoration: none; cursor: pointer; font-weight: 500;"" href=""http://www.cyclismo.org/tutorial/R/tables.html#creating-a-table-from-data"">Creating a Table from Data</a></li> <li style=""box-sizing: border-box; list-style: disc; margin-left: 24px;""><a id=""id2"" class=""reference internal"" style=""box-sizing: border-box; color: #4a9470; text-decoration: none; cursor: pointer; font-weight: 500;"" href=""http://www.cyclismo.org/tutorial/R/tables.html#creating-a-table-directly"">Creating a Table Directly</a></li> <li style=""box-sizing: border-box; list-style: disc; margin-left: 24px;""><a id=""id3"" class=""reference internal"" style=""box-sizing: border-box; color: #4a9470; text-decoration: none; cursor: pointer; font-weight: 500;"" href=""http://www.cyclismo.org/tutorial/R/tables.html#tools-for-working-with-tables"">Tools For Working With Tables</a></li> <li style=""box-sizing: border-box; list-style: disc; margin-left: 24px;""><a id=""id4"" class=""reference internal"" style=""box-sizing: border-box; color: #4a9470; text-decoration: none; cursor: pointer; font-weight: 500;"" href=""http://www.cyclismo.org/tutorial/R/tables.html#graphical-views-of-tables"">Graphical Views of Tables</a></li> </ul> </div> <p><span id=""index-0"" class=""target"" style=""box-sizing: border-box; color: #404040; font-family: Lato, proxima-nova, 'Helvetica Neue', Arial, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #fcfcfc;""></span></p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TKFTKUEI","document","","","ifelse","","","","","http://stackoverflow.com/questions/12125980/how-to-create-a-new-variable-in-a-data-frame-based-on-a-condition","","","2016-10-19 21:52:09","2016-10-19 21:53:33","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IQAJNMZ6","document","","","matix","","","","","http://www.r-tutor.com/r-introduction/matrix/matrix-construction","","","2016-10-19 21:53:57","2016-10-19 21:54:06","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"36EQBV47","document","","","tidying tutorials","","","","","http://www.jvcasillas.com/tidyr_tutorial/","","","2016-10-19 21:55:13","2016-10-19 21:55:23","","","","","","","","","","","","","","","","","","","","","","","<ul> <li>gather()</li> <li>spread()</li> <li>unite()</li> <li>separate()</li> </ul>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FTH8P35K","document","","","data wrangling cheetsheet","","","","","https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf","","","2016-10-19 21:56:19","2016-10-19 21:56:38","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XFZ2WQHH","document","","","Remove Rows From Data Frame where a Row match a String","","","","","http://stackoverflow.com/questions/6650510/remove-rows-from-data-frame-where-a-row-match-a-string","","","2016-10-19 21:57:06","2016-10-19 21:57:19","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JJFMB9XG","document","","","ggplot2 for code","","","","","http://docs.ggplot2.org/current/","","","2016-10-19 21:58:10","2016-10-19 21:58:30","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q39EGXF5","document","","","Swirl","","","","","","","","2016-10-25 15:51:42","2016-10-25 15:51:51","","","","","","","","","","","","","","","","","","","","","","","<h2 style=""box-sizing: border-box; margin-top: 24px; margin-bottom: 16px; font-size: 1.5em; font-weight: 600; line-height: 1.25; padding-bottom: 0.3em; border-bottom: 1px solid #eeeeee; color: #333333; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">Instructions</h2> <p style=""box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: #333333; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">This week you will be acquiring and submitting some work through Github. To do this you will need to have RStudio &amp; Github connected. If you have not already done this, please follow the instructions<span class=""Apple-converted-space"">&nbsp;</span><a style=""box-sizing: border-box; background-color: transparent; color: #4078c0; text-decoration: none;"" href=""http://www.molecularecologist.com/2013/11/using-github-with-r-and-rstudio/"">here</a><span class=""Apple-converted-space"">&nbsp;</span>(Mac) or<span class=""Apple-converted-space"">&nbsp;</span><a style=""box-sizing: border-box; background-color: transparent; color: #4078c0; text-decoration: none;"" href=""http://www.r-bloggers.com/rstudio-and-github/"">here</a><span class=""Apple-converted-space"">&nbsp;</span>(Windows). This can be a non-trivial step, so save some time to do it. If you are having trouble either Tweet your anguish or email me directly. (The crucial step is that in RStudio under Tools -&gt; Global Options -&gt; Git/SVN you must fill in the both the boxes: Git executable and SVN executable with the locations of both of those files.)</p> <p style=""box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: #333333; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;"">Once you have set up this connection we will be using an R package named Swirl, Swirl is an interactive R lesson generator. Your task will be to do an introductory lesson in R and pull the data back to the Github repository.</p> <p style=""box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: #333333; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;""><strong style=""box-sizing: border-box; font-weight: 600;"">Step 1:</strong><span class=""Apple-converted-space"">&nbsp;</span>Fork the class4 repository to your personal Github Account.</p> <p style=""box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: #333333; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;""><strong style=""box-sizing: border-box; font-weight: 600;"">Step 2:</strong><span class=""Apple-converted-space"">&nbsp;</span>Copy the URL for your forked class4 repository.</p> <p style=""box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: #333333; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;""><strong style=""box-sizing: border-box; font-weight: 600;"">Step 3:</strong><span class=""Apple-converted-space"">&nbsp;</span>Open RStudio and start a new project (File -&gt; New Project...)</p> <p style=""box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: #333333; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;""><strong style=""box-sizing: border-box; font-weight: 600;"">Step 4:</strong><span class=""Apple-converted-space"">&nbsp;</span>Within the ""Create Project"" dialog box choose ""Version Control"" and then ""Git: Clone a project from a Git repository""</p> <p style=""box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: #333333; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;""><strong style=""box-sizing: border-box; font-weight: 600;"">Step 5:</strong><span class=""Apple-converted-space"">&nbsp;</span>Paste the URL for your class4 repository under ""Repository URL""</p> <p style=""box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: #333333; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;""><strong style=""box-sizing: border-box; font-weight: 600;"">Step 6:</strong><span class=""Apple-converted-space"">&nbsp;</span>Name the directory ""Class 4 - Swirl"" and save it to a place on your computer that you will be able to locate</p> <p style=""box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: #333333; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;""><strong style=""box-sizing: border-box; font-weight: 600;"">Step 7:</strong><span class=""Apple-converted-space"">&nbsp;</span>Install the ""Swirl"" package either by typing<span class=""Apple-converted-space"">&nbsp;</span><code style=""box-sizing: border-box; font-family: Consolas, 'Liberation Mono', Menlo, Courier, monospace; font-size: 13.6px; padding: 0.2em 0px; margin: 0px; background-color: rgba(0, 0, 0, 0.0392157); border-radius: 3px;"">install.packages(""swirl"")</code><span class=""Apple-converted-space"">&nbsp;</span>into the Console window or installing through the ""packages"" tab on the bottom right window.</p> <p style=""box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: #333333; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;""><strong style=""box-sizing: border-box; font-weight: 600;"">Step 8:</strong><span class=""Apple-converted-space"">&nbsp;</span>Load swirl by typing<span class=""Apple-converted-space"">&nbsp;</span><code style=""box-sizing: border-box; font-family: Consolas, 'Liberation Mono', Menlo, Courier, monospace; font-size: 13.6px; padding: 0.2em 0px; margin: 0px; background-color: rgba(0, 0, 0, 0.0392157); border-radius: 3px;"">library(swirl)</code><span class=""Apple-converted-space"">&nbsp;</span>into the Console window.</p> <p style=""box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: #333333; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;""><strong style=""box-sizing: border-box; font-weight: 600;"">Step 9:</strong><span class=""Apple-converted-space"">&nbsp;</span>Initiate Swirl by typing<span class=""Apple-converted-space"">&nbsp;</span><code style=""box-sizing: border-box; font-family: Consolas, 'Liberation Mono', Menlo, Courier, monospace; font-size: 13.6px; padding: 0.2em 0px; margin: 0px; background-color: rgba(0, 0, 0, 0.0392157); border-radius: 3px;"">swirl()</code></p> <p style=""box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: #333333; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;""><strong style=""box-sizing: border-box; font-weight: 600;"">Step 10:</strong><span class=""Apple-converted-space"">&nbsp;</span>Follow the instructions Swirl gives you to complete a lesson</p> <p style=""box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: #333333; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;""><strong style=""box-sizing: border-box; font-weight: 600;"">Step 11:</strong><span class=""Apple-converted-space"">&nbsp;</span>Once you have completed several lessons and exited the swirl session, type the following code into the RStudio Console window to export your lesson data. (You may need to change the file path in the first line. To do so search for ""history_database"" and replace the file path to point at that location on your computer).</p> <pre style=""box-sizing: border-box; font-family: Consolas, 'Liberation Mono', Menlo, Courier, monospace; font-size: 13.6px; margin-top: 0px; margin-bottom: 16px; font-style: normal; font-variant: normal; font-weight: normal; font-stretch: normal; line-height: 1.45; word-wrap: normal; padding: 16px; overflow: auto; background-color: #f7f7f7; border-radius: 3px; color: #333333; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;""><code style=""box-sizing: border-box; font-family: Consolas, 'Liberation Mono', Menlo, Courier, monospace; font-size: 13.6px; padding: 0px; margin: 0px; background: transparent; border-radius: 3px; word-break: normal; white-space: pre; border: 0px; display: inline; overflow: visible; line-height: inherit; word-wrap: normal;"">    H &lt;-read.table(""~/.rstudio-desktop/history_database"", sep="":"", fill=T, stringsAsFactors=F)      names(H) &lt;- c(""time"", ""answer"")     H$id &lt;- ""YOUR NAME""     write.csv(H, file = ""lesson1.csv"", row.names = FALSE) </code></pre> <p style=""box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: #333333; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;""><strong style=""box-sizing: border-box; font-weight: 600;"">Step 12:</strong><span class=""Apple-converted-space"">&nbsp;</span>Now commit all changes to your cloned repository by clicking the ""Git"" button on the top of the left hand pane and then ""Commit"" from the drop-down menu.</p> <p style=""box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: #333333; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;""><strong style=""box-sizing: border-box; font-weight: 600;"">Step 13:</strong><span class=""Apple-converted-space"">&nbsp;</span>Check all the boxes in the top left of the Review Changes window and describe the nature of your commit in the right hand pane.</p> <p style=""box-sizing: border-box; margin-top: 0px; margin-bottom: 16px; color: #333333; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;""><strong style=""box-sizing: border-box; font-weight: 600;"">Step 14:</strong><span class=""Apple-converted-space"">&nbsp;</span>Once you have commited your assignment, click the ""push"" button in the top right hand of the corner of the window to ""push"" your commit to your online repository.</p> <p style=""box-sizing: border-box; margin-top: 0px; margin-bottom: 0px !important; color: #333333; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;""><strong style=""box-sizing: border-box; font-weight: 600;"">Step 15:</strong><span class=""Apple-converted-space"">&nbsp;</span>Return to the your Github page to check that the files appear there and then create a ""Pull Request"" to submit your work.</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PPRGET2E","document","","Li, Jiaxi","R programming cheatsheet","","","","","","Classnotes and Swirl notes for R programming  - cheatsheet notes","","2016-10-25 15:53:24","2016-10-25 15:54:13","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MWCUCF8P","document","","","Difference between as.data.frame(x) and data.frame(x) - when combining columns","","","","","http://stackoverflow.com/questions/21574250/difference-between-as-data-framex-and-data-framex","","","2016-10-25 16:39:13","2016-10-25 16:39:41","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UNTRBANA","document","","","Principal Component Analysis using R","","","","","https://www.r-bloggers.com/principal-component-analysis-using-r/","","","2016-10-27 16:29:47","2016-10-27 16:30:25","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8CPD68E7","document","","","""Principle Component Aanalysis"" class exercise with confidence datasets","","","","","","","","2016-10-31 21:34:06","2016-10-31 21:34:30","","","","","","","","","","","","","","","","","","","","","","","<p>---<br />title: ""Principle Component Aanalysis""<br />output: html_document<br />---<br />#Data<br />The data you will be using comes from teh Assistments online intelligent tutoring system (https://www.assistments.org/). It describes students working through online math problems. Each student has the following data associated with them:<br /><br />- id<br />- prior_prob_count: How many problems a student has answered in the system prior to this session<br />- prior_percent_correct: The percentage of problems a student has answered correctly prior to this session<br />- problems_attempted: The number of problems the student has attempted in the current session<br />- mean_correct: The average number of correct answers a student made on their first attempt at problems in the current session<br />- mean_hint: The average number of hints a student asked for in the current session<br />- mean_attempt: The average number of attempts a student took to answer a problem in the current session<br />- mean_confidence: The average confidence each student has in their ability to answer the problems in the current session<br /><br />#Start by uploading the data<br />```{r}<br />D1 &lt;-&nbsp; read.table (""Assistments-confidence.csv"", sep = "","") <br /><br />&nbsp; #We won't need to id variable, so remove that.<br /><br />D1 &lt;- dplyr::select(D1, 2:8)<br /><br />```<br /><br />#Create a correlation matrix of the relationships between the variables, including correlation coefficients for each pair of variables/features.<br /><br />```{r}<br />#You can install the corrplot package to plot some pretty correlation matrices (sometimes called correlograms)<br /><br />install.packages(""corrplot"")<br /><br />library(corrplot)<br />library(dplyr)<br /><br />#Rename columns for dataframe<br />names(D1) &lt;- c(""prior_prob_count"", ""prior_percent_correct"", ""problems_attempted"",""mean_correct"",""mean_hint"",""mean_attempt"",""mean_confidence"")<br /><br /># Remove the first row which contains column names not values <br />D1 &lt;- dplyr::slice(D1, 2:343)<br /><br />#Need numeric ""x"" to operate cor function<br />D1$prior_prob_count &lt;- as.numeric(D1$prior_prob_count)<br />D1$prior_percent_correct &lt;- as.numeric(D1$prior_percent_correct)<br />D1$problems_attempted &lt;- as.numeric(D1$problems_attempted)<br />D1$mean_correct &lt;- as.numeric(D1$mean_correct)<br />D1$mean_correct &lt;- as.numeric(D1$mean_correct)<br />D1$mean_hint &lt;- as.numeric(D1$mean_hint)<br />D1$mean_attempt &lt;-as.numeric(D1$mean_attempt)<br />D1$mean_confidence&lt;- as.numeric(D1$mean_confidence)<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;<br />#Generate pairwise correlations<br />COR &lt;- cor(D1)<br /><br />corrplot(COR, order=""AOE"", method=""circle"", tl.pos=""lt"", type=""upper"",&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;<br />tl.col=""black"", tl.cex=0.6, tl.srt=45, <br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; addCoef.col=""black"", addCoefasPercent = TRUE,<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; sig.level=0.50, insig = ""blank"")<br /><br />#Study your correlogram image and save it, you will need it later<br />#Interpretations - each number is corrlation multipled by 100<br /><br />```<br /><br />#Create a new data frame with the mean_correctvariables removed<br /><br />```{r}<br />D2 &lt;- dplyr::select(D1, 1:3,5:7)<br />#remove the least variance as well- for thereasons that explained not much <br /><br />#The, scale and center your data for easier interpretation <br /># Center to close to 0/ the mean<br />D2 &lt;- scale(D2, center = TRUE)<br />```<br /><br />#Now run the PCA on the new data frame<br /><br />```{r}<br />pca &lt;- prcomp(D2, scale = TRUE)<br />```<br /><br />#Although the algorithm does not generate the eigenvalues directly for us, we can print a list of the standard deviation of the variance accounted for by each component.<br /><br />```{r}<br />pca$sdev<br /><br />#To convert this into variance accounted for we can square it, these numbers are proportional to the eigenvalue<br /><br />pca$sdev^2<br /><br />#A summary of our pca will give us the proportion of variance accounted for by each component<br /><br />summary(pca)<br />#Note! proportion of variance (is proportion, and add all to 1)in summary is not equal to actual variance computed above<br /><br />#We can lot this to get an idea of which components we should keep and which we should drop<br /><br />plot(pca, type = ""lines"")<br />##since pca provided with the maximum of varaition of all variables in some ways(we don't know) and projected in multi-dimensional coordination. The plot here represents all projections, and pc6 is the least variation contains all varaibles. Which means, least representative, as the following correlation will show that: the least projection still counts to some correlation, really wastes of total correlation . (so thinking about dropping down PC6, eventhough we don't really do that)<br />```<br /><br />#Think about which components you would drop and make a decision<br />#remove the least variance as well- for thereasons that explained not much (#6,mean_confidence)<br /><br />```{r}<br />#Now, create a data frame of the transformed data from your pca.<br />#pca transform all data into new datasets<br />D3 &lt;- as.data.frame(pca$x)<br /><br />#Attach the variable ""mean_correct"" from your original data frame to D3.<br /><br />D4 &lt;- cbind(D3, as.data.frame(D1$mean_correct))<br />#data.frame/as.data.frame/cbind can all be used for combine columns<br /><br />#Now re-run your scatterplots and correlations between the transformed data and mean_correct. If you had dropped some components would you have lost important infomation about mean_correct?<br /><br />COR2 &lt;- cor(D4) <br /><br />corrplot(COR2, order=""AOE"", method=""circle"", tl.pos=""lt"", type=""upper"",&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;<br />tl.col=""black"", tl.cex=0.6, tl.srt=45, <br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; addCoef.col=""black"", addCoefasPercent = TRUE,<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; sig.level=0.50, insig = ""blank"")<br /><br />###Interpretation: Transformed data include all columns except mean_correctvariables, and adds on original data of mean_correct; we can see a high correlation between PC1 and mean-correct, which consider PC1 as the most meaningful to explain the relationship between compositions of PC1 towards mean_correct. The least projection pc6 still counts to some correlations, which really wastes of total correlations for other PCs with mean-correct.<br /><br />```<br /><br />#print out the eigenvectors (often called loadings) for the components you generated:<br />```{r}<br />pca$rotation<br /><br />#Examine the eigenvectors, notice that they are a little difficult to interpret. It is much easier to make sense of them if we make them proportional within each component<br /><br />#eigenvectors are propotional to those projection. All eigenvalue and eigenvectors for different variables composite together (in some way automatically) to form up a projection in multi-dimensional coornination.<br />loadings &lt;- abs(pca$rotation) #abs() will make all eigenvectors positive<br /><br />table1 &lt;- sweep(loadings, 2, colSums(loadings),""/"") <br />#sweep() computes each row as a proportion of the column. (There must be a way to do this with dplyr()?)<br />```<br /><br />#Now examine your components and try to come up with substantive descriptions of what some might represent?<br /><br />```{r}<br />#You can generate a biplot to help you, though these can be a bit confusing. They plot the transformed data by the first two components. Therefore, the axes represent the direction of maximum variance. Then mapped onto this point cloud are the original directions of the variables, depicted as red arrows. It is supposed to provide a visualization of which variables ""go together"". Variables that possibly represent the same underlying construct point in the same direction. &nbsp;<br /><br />biplot(pca)<br />#Interpretation:In the preceding image, known as a biplot, we can see the two principal components (PC1 and PC2) of the crimtab dataset. The red arrows represent the loading vectors, which represent how the feature space varies along the principal component vectors.<br />#From the plot, we can see that the first principal component vector, PC1, more or less places equal weight on three features: problems_attemp &amp; mean_confidence. This means that these three features are more correlated with each other than the rests variables.<br />#In the second principal component, PC2 places more weight on mean_hints &amp;mean_atemp than the 3 features which are less correlated with them. <br />```<br /><br />#Calculate values for each student that represent these your composite variables and then create a new correlogram showing their relationship to mean_correct.<br />```{r}<br />#composite variables :enlarge the effects of eigenvectors towards composition of projection <br />#from each PC, varaibles contribute different weights toward each PC, so create new name for the most weights with expression.<br /><br />D2 &lt;- as.data.frame(D2)<br />###store in a varaible added automatically to D2<br />D2$Persistence &lt;- (D2$prior_prob_count *0.02346643)+(D2$prior_percent_correct*0.18654306)+(D2$problems_attempted*0.09963448)+(D2$mean_hint*0.31489715)+(D2$mean_attempt*0.31314664)+(D2$mean_confidence*0.06231224)<br /><br />D2$ProblemsUnderstand &lt;- (D2$prior_percent_correct*0.003976708)+(D2$prior_percent_correct*0.016452382)+(D2$problems_attempted*0.376584209)+(D2$mean_hint*0.163987876)+(D2$mean_attempt*0.043179730)+(D2$mean_confidence*0.395819095)<br /><br />D2$probcount &lt;- (D2$prior_prob_count*0.53261479)+(D2$prior_percent_correct*0.04794137)+(D2$problems_attempted*0.18321852)+(D2$mean_hint*0.02425319)+(D2$mean_attempt* 0.03639153)+(D2$mean_confidence* 0.17558059)<br /><br />D2$confidence &lt;- (D2$prior_prob_count*0.17718963)+(D2$prior_percent_correct*0.20244021)+(D2$problems_attempted*0.21590171)+(D2$mean_hint*0.07862138)+(D2$mean_attempt*0.07324022)+(D2$mean_confidence*0.25260685)<br /><br />D2$correction &lt;- (D2$prior_prob_count* 0.07160263)+ (D2$prior_percent_correct* 0.38945695)+(D2$problems_attempted* 0.20064401)+(D2$mean_hint* 0.02158017)+(D2$mean_attempt* 0.17024218)+(D2$mean_confidence*&nbsp; 0.14647407)<br /><br />D2$hints &lt;- (D2$prior_prob_count*0.05431036)<br />&nbsp;+(D2$prior_percent_correct * 0.09114058)+ (D2$problems_attempted *0.09174208)+(D2$mean_hint*0.37176236)+(D2$mean_attempt *0.35915325)+(D2$mean_confidence *0.03189138)<br />```<br /><br />## Now creating new algorithm for composite variables <br />```{r}<br />###select only new varaibles for new dataframe D3<br />D3 &lt;- dplyr::select(D2, 7:12)<br /><br />###combined with mean_correct data<br />D4 &lt;- cbind(D3, as.data.frame(D1$mean_correct))<br /><br />### reveal the correlation between new composite variables and mean_correct<br />COR3 &lt;- cor(D4)<br /><br />corrplot(COR3, order=""AOE"", method=""circle"", tl.pos=""lt"", type=""upper"",&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;<br />tl.col=""black"", tl.cex=0.6, tl.srt=45, <br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; addCoef.col=""black"", addCoefasPercent = TRUE,<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; sig.level=0.50, insig = ""blank"")<br /><br />#Explainations: new variables are created based&nbsp; on original datasets' wegihts (eigenvectors) contribute to each PC, which means, origianl varaibles have varied importance to each projection. And we tried to see the correlation between new varaibles (under composition to each PC) and mean_correct.<br /><br /># What can be concluded from the corrplot is that mean_correct is negative correlated (-29%) with persistence (weigheted in largest by mean_hint &amp;mean_attemp). This can be expained as the better correction, the less needed in persistence for keeping trying. <br /><br />#Second, there is a 30% positive corrlation between based_correction(composited mostly by prior_percent_correct) and mean_correct; which can be explanined as if students doing well in previous works, they are considered to continue their success in their future studies.<br /><br />#Third, there is a 22% positive corrlation between confidence and mean_correct. Confidence is composed with mean_confidence and problems_attemp. Thus, if students try more times with increased confidence, there is a positive result for their correctness. <br />```<br /><br /></p>","/Users/jiaxil/Desktop/CU/CU_HWS/Autumn 2016/EDM/assignment4/assignment4- excercise.Rmd","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2N3PBVPE","document","","Li, Jiaxi","Assignment4 -humor exercise","","","","","","","","2016-10-31 21:34:55","2016-10-31 21:35:13","","","","","","","","","","","","","","","","","","","","","","","<p>---<br />title: ""Humor-excercise""<br />author: ""jiaxili""<br />date: ""October 27, 2016""<br />output: html_document<br />---<br /><br />#Start by uploading the data<br />```{r}<br />K1 &lt;-&nbsp; read.table (""humor_data.csv"", sep = "","") <br /><br />install.packages(""corrplot"")<br /><br />library(corrplot)<br />library(dplyr)<br /><br />```<br /><br />#Arrange datasets<br />```{r}<br />#Rename columns for dataframe<br />names(K1) &lt;- c(""Q1"", ""Q2"",""Q3"",""Q4"",""Q5"",""Q6"",""Q7"",""Q8"",""Q9"",""Q10"",""Q11"",""Q12"",""Q13"",""Q14"",""Q15"",""Q16"",""Q17"",""Q18"",""Q19"",""Q20"",""Q21"",""Q22"",""Q23"",""Q24"",""Q25"",""Q26"",""Q27"",""Q28"",""Q29"",""Q30"",""Q31"",""Q32"",""affiliative"",""selfenhancing"",""agressive"",""selfdefeating"",""age"",""gender"",""accuracy"" )<br /><br /># Remove the first row which contains column names not values <br />K1 &lt;- dplyr::slice(K1, 2:1072)<br />```<br /><br />#Prestep of pca<br />```{r}<br />#Need numeric ""x"" to operate cor function<br />K1$Q1 &lt;-as.numeric(K1$Q1)<br />K1$Q2 &lt;-as.numeric(K1$Q2)<br />K1$Q3 &lt;-as.numeric(K1$Q3)<br />K1$Q4 &lt;-as.numeric(K1$Q4)<br />K1$Q5 &lt;-as.numeric(K1$Q5)<br />K1$Q6 &lt;-as.numeric(K1$Q6)<br />K1$Q7 &lt;-as.numeric(K1$Q7)<br />K1$Q8 &lt;-as.numeric(K1$Q8)<br />K1$Q9 &lt;-as.numeric(K1$Q9)<br />K1$Q10 &lt;-as.numeric(K1$Q10)<br />K1$Q11 &lt;-as.numeric(K1$Q11)<br />K1$Q12 &lt;-as.numeric(K1$Q12)<br />K1$Q13 &lt;-as.numeric(K1$Q13)<br />K1$Q14 &lt;-as.numeric(K1$Q14)<br />K1$Q15 &lt;-as.numeric(K1$Q15)<br />K1$Q16 &lt;-as.numeric(K1$Q16)<br />K1$Q17 &lt;-as.numeric(K1$Q17)<br />K1$Q18 &lt;-as.numeric(K1$Q18)<br />K1$Q19 &lt;-as.numeric(K1$Q19)<br />K1$Q20 &lt;-as.numeric(K1$Q20)<br />K1$Q21 &lt;-as.numeric(K1$Q21)<br />K1$Q22 &lt;-as.numeric(K1$Q22)<br />K1$Q23 &lt;-as.numeric(K1$Q23)<br />K1$Q24 &lt;-as.numeric(K1$Q24)<br />K1$Q25 &lt;-as.numeric(K1$Q25)<br />K1$Q26 &lt;-as.numeric(K1$Q26)<br />K1$Q27 &lt;-as.numeric(K1$Q27)<br />K1$Q28 &lt;-as.numeric(K1$Q28)<br />K1$Q29 &lt;-as.numeric(K1$Q29)<br />K1$Q30 &lt;-as.numeric(K1$Q30)<br />K1$Q31 &lt;-as.numeric(K1$Q31)<br />K1$Q32 &lt;-as.numeric(K1$Q32)<br />K1$affiliative &lt;-as.numeric(K1$affiliative)<br />K1$selfenhancing &lt;-as.numeric(K1$selfenhancing)<br />K1$agressive &lt;-as.numeric(K1$agressive)<br />K1$selfdefeating &lt;-as.numeric(K1$selfdefeating)<br />K1$age &lt;-as.numeric(K1$age)<br />K1$gender &lt;-as.numeric(K1$gender)<br />K1$accuracy &lt;-as.numeric(K1$accuracy)<br />```<br /><br />#Generate pairwise correlations for original datasets<br />```{r}<br />COR &lt;- cor(K1)<br /><br />corrplot(COR, order=""AOE"", method=""circle"", tl.pos=""lt"", type=""upper"",&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;<br />tl.col=""black"", tl.cex=0.6, tl.srt=45, <br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; addCoef.col=""black"", addCoefasPercent = TRUE,<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; sig.level=0.50, insig = ""blank"")<br />```<br /><br />#Create a new data frame with 4 scale scores of the HSQ removed<br />```{r}<br />K2 &lt;- dplyr::select(K1, 1:32,37:39)<br /><br />#Then scale and center data for easier interpretation <br /># Center to close to 0/ the mean<br />K2 &lt;- scale(K2, center = TRUE)<br /><br />K2&lt;- as.data.frame(K2)<br />```<br /><br />#Now run the PCA on the new data frame<br />```{r}<br />pca &lt;- prcomp(K2, scale = TRUE)<br /><br />#Summary of the variance of PCA<br />pca$sdev<br />pca$sdev^2<br />summary(pca)<br />plot(pca, type = ""lines"")<br /><br /># Explanations: PC6-PC10 are explaning the least variance of all varaibles, and considered leaste meaningful<br />```<br /><br />#pca transform all data into new datasets<br />```{r}<br />K3 &lt;- as.data.frame(pca$x)<br /><br />#Attach the 4 variables scale scores of the HSQ&nbsp; from your original data frame to pca respectively.<br />Combined_aff &lt;- cbind(K3, as.data.frame(K1$affiliative))<br />Combined_enh &lt;- cbind(K3, as.data.frame(K1$selfenhancing))<br />Combined_agg &lt;- cbind(K3, as.data.frame(K1$agressive))<br />Combined_def &lt;- cbind(K3, as.data.frame(K1$selfdefeating))<br />``` <br /><br />#Scatterplots and correlations between the transformed data and scale scores of the HSQ<br />```{r}<br />#for transformed datasets with affiliative results<br />COR_aff &lt;- cor(Combined_aff)<br /><br />corrplot(COR_aff, order=""AOE"", method=""circle"", tl.pos=""lt"", type=""upper"",&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;<br />tl.col=""black"", tl.cex=0.6, tl.srt=20, <br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; addCoef.col=""black"", addCoefasPercent = TRUE,<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; sig.level=0.50, insig = ""blank"")<br /><br />#Explanations: there is a&nbsp; high negative correlation for PC1,PC2 and PC4 with affiliative result.<br />```<br /><br />```{r}<br />#for transformed datasets with selfenhancing results<br />COR_enh &lt;- cor(Combined_enh)<br /><br />corrplot(COR_enh, order=""AOE"", method=""circle"", tl.pos=""lt"", type=""upper"",&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;<br />tl.col=""black"", tl.cex=0.6, tl.srt=20, <br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; addCoef.col=""black"", addCoefasPercent = TRUE,<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; sig.level=0.50, insig = ""blank"")<br />#Explanations: there is a negative high correlation for PC1 and PC3, positive high correlation for PC5 with elfenhancing result.<br />```<br /><br />```{r}<br />#for transformed datasets with aggressive results<br />COR_agg &lt;- cor(Combined_agg)<br /><br />corrplot(COR_agg, order=""AOE"", method=""circle"", tl.pos=""lt"", type=""upper"",&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;<br />tl.col=""black"", tl.cex=0.6, tl.srt=20, <br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; addCoef.col=""black"", addCoefasPercent = TRUE,<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; sig.level=0.50, insig = ""blank"")<br />#Explanations: there is a positive high correlation between PC5 and PC6 with aggressive result.<br /><br />```<br /><br />```{r}<br />#for transformed datasets with selfdefeating results<br />COR_def &lt;- cor(Combined_def)<br /><br />corrplot(COR_def, order=""AOE"", method=""circle"", tl.pos=""lt"", type=""upper"",&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;<br />tl.col=""black"", tl.cex=0.6, tl.srt=20, <br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; addCoef.col=""black"", addCoefasPercent = TRUE,<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; sig.level=0.50, insig = ""blank"")<br />#Explanations: there is a positive high correlation between PC2,and negative high correlation for PC1 and PC3 with selfdefeating result.<br />```<br /><br /><br />#print out the eigenvectors (often called loadings) for the components generated:<br />```{r}<br />pca$rotation<br />loadings &lt;- abs(pca$rotation) <br />table &lt;- sweep(loadings, 2, colSums(loadings),""/"") <br /><br />#From table: <br />#PC1 is weighted mostly by Q1, Q5, Q17 and Q26;<br />#PC2 is relied mostly on Q7, Q8 and Q20;<br />#PC3 is composited mostly with Q4, Q7, Q23, Q24, and Q32;<br />#PC4 is ... with Q10,Q17,and Q30;<br />#PC5 is ... with age and Q22;<br />#PC6 is ... with Q5,Q11 age and gender;<br /># and so on ...<br />```<br /><br />#generate a biplot to plot the transformed data by the first two components. Therefore, the axes represent the direction of maximum variance. Then mapped onto this point cloud are the original directions of the variables, depicted as red arrows. It is supposed to provide a visualization of which variables ""go together"". Variables that possibly represent the same underlying construct point in the same direction. &nbsp;<br />```{r}<br />biplot(pca) ##?<br /><br />#Interpretation:In the preceding image, known as a biplot, we can see the two principal components (PC1 and PC2) of the crimtab dataset. The red arrows represent the loading vectors, which represent how the feature space varies along the principal component vectors.<br /><br />#From the plot, we can see that the first groups of principal component vector, PC1 more or less places equal weight on features: Q7,Q11,Q15,Q16,Q23,Q31 This means that these three features are more correlated with each other to composite PC1 than the rest variables. &lt;aggressive&gt;<br /><br />#In the second principal component, PC2 places more weight on Q2,Q5,Q6,Q10,Q14,Q21,Q26 and Q30 than others. &lt;selfenhancing&gt;<br /><br />#Moreover, from the graph, Q9,Q1,Q17,and Q25 form another group of eigenvectors.&lt;affiliative&gt;<br /><br />#Lastly, there is a group composited with Q28,Q4,Q8,Q32,Q20 and Q12.&lt;selfdefeating&gt;<br />```<br /><br />#Compring findings with existed outcomes of scale scores of the HSQ:<br />```{r}<br />#According to the humor_codebook.txt The four scale scores of the HSQ were calculated as such (php code):<br /><br />#affiliative. round(((6-$_POST['Q1']) + $_POST['Q5'] + (6-$_POST['Q9']) + $_POST['Q13'] + (6-$_POST['Q17']) + $_POST['Q21'] + (6-$_POST['Q25']) + (6-$_POST['Q29']))/8, 1);<br />#selfenhancing. round(($_POST['Q2'] + $_POST['Q6'] + $_POST['Q10'] + $_POST['Q14'] + $_POST['Q18'] + $_POST['Q22'] + $_POST['Q26'] + $_POST['Q30'])/8,1);<br />#aggressive. round(($_POST['Q3']+ $_POST['Q7'] + $_POST['Q11'] + $_POST['Q15'] + $_POST['Q19'] + $_POST['Q23'] + $_POST['Q27'] + $_POST['Q31'])/8,1);<br />#selfdefeating. round(($_POST['Q4'] + $_POST['Q8'] + $_POST['Q12'] + $_POST['Q16'] + $_POST['Q20'] + $_POST['Q24'] + $_POST['Q28'] + $_POST['Q32'])/8,1);<br /><br /># This is actually the same as the above biplot shows.&nbsp; Without grouping data with composite variables calculated, biasness occurred. However, it is still reasonable to interprete the results without composite variables, and its has shown clear the same interpretation corresponding to what have concluded by codebook .</p>","/Users/jiaxil/Desktop/CU/CU_HWS/Autumn 2016/EDM/assignment4/Humor- excercise.Rmd","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CHPQIFCQ","document","","","","","","","","","","","2016-11-01 20:14:35","2016-11-01 20:14:35","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SWUR9HIE","document","","","","","","","","","","","2016-11-01 20:19:51","2016-11-01 20:19:51","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E7AH66BQ","book","","Perna","The State of College Access and Completion : Improving College Success for Students from Underrepresented Groups","","","","","http://site.ebrary.com.eduproxy.tc-library.org:8080/lib/teacherscollege/reader.action?ppg=1&docID=10736724&tm=1437414546429","","","2016-11-30 18:19:32","2016-11-30 18:19:53","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"87CPVFPQ","document","","","Computing Classification Evaluation Metrics in R","","","","","http://blog.revolutionanalytics.com/2016/03/com_class_eval_metrics_r.html","","","2016-12-13 18:18:44","2016-12-13 18:18:57","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FCKZ7S8F","document","","","Calculate the F1 score of precision and recall in R","","","","","http://stats.stackexchange.com/questions/138690/calculate-the-f1-score-of-precision-and-recall-in-r","","","2016-12-13 18:47:18","2016-12-13 18:47:39","","","","","","","","","","","","","","","","","","","","","","","<pre class=""default prettyprint prettyprinted"" style=""margin: 0px 0px 1em; padding: 5px; border: 0px; font-size: 13px; width: auto; max-height: 600px; overflow: auto; font-family: Consolas, Menlo, Monaco, 'Lucida Console', 'Liberation Mono', 'DejaVu Sans Mono', 'Bitstream Vera Sans Mono', 'Courier New', monospace, sans-serif; background-color: #eff0f1; display: block; color: #393318; word-wrap: normal; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: left; text-indent: 0px; text-transform: none; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px;""><code style=""margin: 0px; padding: 0px; border: 0px; font-size: 13px; font-family: Consolas, Menlo, Monaco, 'Lucida Console', 'Liberation Mono', 'DejaVu Sans Mono', 'Bitstream Vera Sans Mono', 'Courier New', monospace, sans-serif; background-color: #eff0f1; white-space: inherit;""><span class=""pln"" style=""margin: 0px; padding: 0px; border: 0px; font-size: 13px; color: #303336;"">precision </span><span class=""pun"" style=""margin: 0px; padding: 0px; border: 0px; font-size: 13px; color: #303336;"">=</span><span class=""pln"" style=""margin: 0px; padding: 0px; border: 0px; font-size: 13px; color: #303336;""> TP </span><span class=""pun"" style=""margin: 0px; padding: 0px; border: 0px; font-size: 13px; color: #303336;"">/</span><span class=""pun"" style=""margin: 0px; padding: 0px; border: 0px; font-size: 13px; color: #303336;"">(</span><span class=""pln"" style=""margin: 0px; padding: 0px; border: 0px; font-size: 13px; color: #303336;"">TP </span><span class=""pun"" style=""margin: 0px; padding: 0px; border: 0px; font-size: 13px; color: #303336;"">+</span><span class=""pln"" style=""margin: 0px; padding: 0px; border: 0px; font-size: 13px; color: #303336;""> FP</span><span class=""pun"" style=""margin: 0px; padding: 0px; border: 0px; font-size: 13px; color: #303336;"">)</span><span class=""pln"" style=""margin: 0px; padding: 0px; border: 0px; font-size: 13px; color: #303336;""> recall </span><span class=""pun"" style=""margin: 0px; padding: 0px; border: 0px; font-size: 13px; color: #303336;"">=</span><span class=""pln"" style=""margin: 0px; padding: 0px; border: 0px; font-size: 13px; color: #303336;""> TP </span><span class=""pun"" style=""margin: 0px; padding: 0px; border: 0px; font-size: 13px; color: #303336;"">/</span><span class=""pun"" style=""margin: 0px; padding: 0px; border: 0px; font-size: 13px; color: #303336;"">(</span><span class=""pln"" style=""margin: 0px; padding: 0px; border: 0px; font-size: 13px; color: #303336;"">TP </span><span class=""pun"" style=""margin: 0px; padding: 0px; border: 0px; font-size: 13px; color: #303336;"">+</span><span class=""pln"" style=""margin: 0px; padding: 0px; border: 0px; font-size: 13px; color: #303336;""> FN</span><span class=""pun"" style=""margin: 0px; padding: 0px; border: 0px; font-size: 13px; color: #303336;"">)</span></code></pre> <p style=""margin: 0px 0px 1em; padding: 0px; border: 0px; font-size: 15px; clear: both; color: #242729; font-family: Arial, 'Helvetica Neue', Helvetica, sans-serif; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: normal; letter-spacing: normal; orphans: 2; text-align: left; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: rgba(252, 251, 248, 0.901961);"">with<span class=""Apple-converted-space"">&nbsp;</span><code style=""margin: 0px; padding: 1px 5px; border: 0px; font-size: 13px; font-family: Consolas, Menlo, Monaco, 'Lucida Console', 'Liberation Mono', 'DejaVu Sans Mono', 'Bitstream Vera Sans Mono', 'Courier New', monospace, sans-serif; background-color: #eff0f1; white-space: pre-wrap;"">TP</code><span class=""Apple-converted-space"">&nbsp;</span>= True positives,<span class=""Apple-converted-space"">&nbsp;</span><code style=""margin: 0px; padding: 1px 5px; border: 0px; font-size: 13px; font-family: Consolas, Menlo, Monaco, 'Lucida Console', 'Liberation Mono', 'DejaVu Sans Mono', 'Bitstream Vera Sans Mono', 'Courier New', monospace, sans-serif; background-color: #eff0f1; white-space: pre-wrap;"">FP</code><span class=""Apple-converted-space"">&nbsp;</span>= False positives and<span class=""Apple-converted-space"">&nbsp;</span><code style=""margin: 0px; padding: 1px 5px; border: 0px; font-size: 13px; font-family: Consolas, Menlo, Monaco, 'Lucida Console', 'Liberation Mono', 'DejaVu Sans Mono', 'Bitstream Vera Sans Mono', 'Courier New', monospace, sans-serif; background-color: #eff0f1; white-space: pre-wrap;"">FN</code><span class=""Apple-converted-space"">&nbsp;</span>= false negatives. Therefore, precision is the fraction of retrieved instances that are relevant, while recall is the fraction of relevant instances that are retrieved (like<span class=""Apple-converted-space"">&nbsp;</span><a style=""margin: 0px; padding: 0px; border: 0px; font-size: 15px; color: #d4876c; text-decoration: none; cursor: pointer;"" rel=""nofollow"" href=""https://en.wikipedia.org/wiki/Precision_and_recall"">wikipedia</a><span class=""Apple-converted-space"">&nbsp;</span>puts it).</p>","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5U93EDBS","document","","","roll-pitch-and-yaw","","","","","http://howthingsfly.si.edu/flight-dynamics/roll-pitch-and-yaw","","","2016-12-19 08:14:42","2016-12-19 08:15:02","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""